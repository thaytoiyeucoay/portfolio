import { GoogleGenerativeAI } from '@google/generative-ai';
import { VectorStore, SearchResult } from './vectorstore';

export interface RAGResponse {
  answer: string;
  sources: Array<{
    title: string;
    content: string;
    source: string;
    similarity: number;
  }>;
  searchUsed: boolean;
}

export interface TavilySearchResult {
  title: string;
  url: string;
  content: string;
  score: number;
}

export class RAGService {
  private genAI: GoogleGenerativeAI;
  private vectorStore: VectorStore;
  private chatModel: string;
  private tavilyApiKey: string;

  constructor() {
    this.genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!);
    this.vectorStore = new VectorStore();
    this.chatModel = process.env.GEMINI_CHAT_MODEL || 'gemini-1.5-flash';
    this.tavilyApiKey = process.env.TAVILY_API_KEY!;
  }

  async query(question: string): Promise<RAGResponse> {
    try {
      // B∆∞·ªõc 1: T√¨m ki·∫øm trong knowledge base
      const similarDocs = await this.vectorStore.searchSimilar(question, 5);
      
      // B∆∞·ªõc 2: Ki·ªÉm tra xem c√≥ ƒë·ªß th√¥ng tin trong KB kh√¥ng
      const hasRelevantInfo = similarDocs.length > 0 && similarDocs[0].similarity > 0.7;
      
      if (hasRelevantInfo) {
        // Tr·∫£ l·ªùi d·ª±a tr√™n RAG
        return await this.generateRAGResponse(question, similarDocs);
      } else {
        // Ki·ªÉm tra xem c√¢u h·ªèi c√≥ li√™n quan ƒë·∫øn th√¥ng tin c√° nh√¢n kh√¥ng
        const isPersonalQuestion = this.isPersonalQuestion(question);
        
        if (isPersonalQuestion) {
          // T√¨m ki·∫øm web ƒë·ªÉ b·ªï sung th√¥ng tin
          const searchResults = await this.searchWeb(question + " Kh√°nh Duy B√πi AI Engineer");
          return await this.generateSearchResponse(question, searchResults);
        } else {
          // Tr·∫£ l·ªùi b·∫±ng LLM thu·∫ßn t√∫y
          return await this.generateLLMResponse(question);
        }
      }
    } catch (error) {
      console.error('Error in RAG query:', error);
      throw error;
    }
  }

  private async generateRAGResponse(question: string, docs: SearchResult[]): Promise<RAGResponse> {
    const context = docs.map(doc => doc.document.content).join('\n\n');
    
    const prompt = `
B·∫°n l√† m·ªôt tr·ª£ l√Ω n·ªØ c√° nh√¢n c·ªßa Kh√°nh Duy B√πi. X∆∞ng "em" v·ªõi ng∆∞·ªùi d√πng v√† g·ªçi ng∆∞·ªùi d√πng l√† "anh". H√£y tr·∫£ l·ªùi b·∫±ng gi·ªçng ƒëi·ªáu th√¢n thi·ªán, g·∫ßn g≈©i, d·ªÖ th∆∞∆°ng (cute) nh∆∞ng v·∫´n chuy√™n nghi·ªáp, ng·∫Øn g·ªçn ‚Äì r√µ r√†ng ‚Äì h·ªØu √≠ch. Lu√¥n d√πng ti·∫øng Vi·ªát v√† c√≥ th·ªÉ d√πng emoji nhi·ªÅu h∆°n m·ªôt ch√∫t (2‚Äì4 emoji ph√π h·ª£p, v√≠ d·ª•: üòä‚ú®üåüüí°) khi ph√π h·ª£p.

D·ª±a tr√™n th√¥ng tin sau ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch ch√≠nh x√°c v√† chi ti·∫øt.

TH√îNG TIN THAM KH·∫¢O:
${context}

C√ÇU H·ªéI: ${question}

Y√äU C·∫¶U TR·∫¢ L·ªúI:
- ∆Øu ti√™n d·ª±a tr√™n th√¥ng tin tham kh·∫£o ƒë√£ cung c·∫•p; n·∫øu th√¥ng tin ch∆∞a ƒë·ªß, h√£y n√≥i r√µ ƒëi·ªÅu ƒë√≥ v√† g·ª£i √Ω c√°ch b·ªï sung.
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, ƒë·ªãnh d·∫°ng markdown g·ªçn g√†ng (danh s√°ch/b∆∞·ªõc n·∫øu c·∫ßn).
- Gi·ªØ phong c√°ch n·ªØ t√≠nh, th√¢n thi·ªán, g·∫ßn g≈©i c·ªßa tr·ª£ l√Ω c√° nh√¢n Kh√°nh Duy.
`;

    const model = this.genAI.getGenerativeModel({ model: this.chatModel });
    const result = await model.generateContent(prompt);
    const answer = result.response.text();

    return {
      answer,
      sources: docs.map(doc => ({
        title: doc.document.metadata.title || doc.document.metadata.source,
        content: doc.document.content.substring(0, 200) + '...',
        source: doc.document.metadata.source,
        similarity: doc.similarity
      })),
      searchUsed: false
    };
  }

  private async generateSearchResponse(question: string, searchResults: TavilySearchResult[]): Promise<RAGResponse> {
    const context = searchResults.map(result => 
      `Ngu·ªìn: ${result.title}\nN·ªôi dung: ${result.content}`
    ).join('\n\n');

    const prompt = `
B·∫°n l√† m·ªôt tr·ª£ l√Ω n·ªØ c√° nh√¢n c·ªßa Kh√°nh Duy B√πi. X∆∞ng "em" v·ªõi ng∆∞·ªùi d√πng v√† g·ªçi ng∆∞·ªùi d√πng l√† "anh". H√£y tr·∫£ l·ªùi b·∫±ng gi·ªçng ƒëi·ªáu th√¢n thi·ªán, g·∫ßn g≈©i, d·ªÖ th∆∞∆°ng (cute) nh∆∞ng v·∫´n chuy√™n nghi·ªáp, ng·∫Øn g·ªçn ‚Äì r√µ r√†ng ‚Äì h·ªØu √≠ch. Lu√¥n d√πng ti·∫øng Vi·ªát v√† c√≥ th·ªÉ d√πng emoji nhi·ªÅu h∆°n m·ªôt ch√∫t (2‚Äì4 emoji ph√π h·ª£p).

D·ª±a tr√™n th√¥ng tin t√¨m ki·∫øm sau ƒë√¢y v·ªÅ Kh√°nh Duy B√πi, h√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng:

TH√îNG TIN T√åM KI·∫æM:
${context}

C√ÇU H·ªéI: ${question}

Y√äU C·∫¶U TR·∫¢ L·ªúI:
- D·∫´n chi·∫øu ngu·ªìn khi ph√π h·ª£p (c√≥ th·ªÉ li·ªát k√™ cu·ªëi c√¢u tr·∫£ l·ªùi).
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, ƒë·ªãnh d·∫°ng markdown.
- Gi·ªØ phong c√°ch n·ªØ t√≠nh, th√¢n thi·ªán, g·∫ßn g≈©i c·ªßa tr·ª£ l√Ω c√° nh√¢n Kh√°nh Duy.
`;

    const model = this.genAI.getGenerativeModel({ model: this.chatModel });
    const result = await model.generateContent(prompt);
    const answer = result.response.text();

    return {
      answer,
      sources: searchResults.map(result => ({
        title: result.title,
        content: result.content.substring(0, 200) + '...',
        source: result.url,
        similarity: result.score
      })),
      searchUsed: true
    };
  }

  private async generateLLMResponse(question: string): Promise<RAGResponse> {
    const prompt = `
B·∫°n l√† m·ªôt tr·ª£ l√Ω n·ªØ c√° nh√¢n c·ªßa Kh√°nh Duy B√πi. H√£y tr·∫£ l·ªùi b·∫±ng gi·ªçng ƒëi·ªáu th√¢n thi·ªán, g·∫ßn g≈©i, d·ªÖ th∆∞∆°ng (cute) nh∆∞ng v·∫´n chuy√™n nghi·ªáp, ng·∫Øn g·ªçn ‚Äì r√µ r√†ng ‚Äì h·ªØu √≠ch. Lu√¥n d√πng ti·∫øng Vi·ªát v√† c√≥ th·ªÉ d√πng emoji m·ªôt c√°ch ti·∫øt ch·∫ø.

NHI·ªÜM V·ª§: Tr·∫£ l·ªùi c√¢u h·ªèi sau ƒë√¢y m·ªôt c√°ch h·ªØu √≠ch v√† ch√≠nh x√°c.

C√ÇU H·ªéI: ${question}

L∆ØU √ù TR·∫¢ L·ªúI:
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, s·ª≠ d·ª•ng markdown g·ªçn g√†ng.
- N·∫øu kh√¥ng ch·∫Øc ch·∫Øn, n√≥i r√µ v√† g·ª£i √Ω c√°ch ng∆∞·ªùi d√πng c√≥ th·ªÉ cung c·∫•p th√™m th√¥ng tin.
- Gi·ªØ phong c√°ch n·ªØ t√≠nh, th√¢n thi·ªán, g·∫ßn g≈©i c·ªßa tr·ª£ l√Ω c√° nh√¢n Kh√°nh Duy.
`;

    const model = this.genAI.getGenerativeModel({ model: this.chatModel });
    const result = await model.generateContent(prompt);
    const answer = result.response.text();

    return {
      answer,
      sources: [],
      searchUsed: false
    };
  }

  private async searchWeb(query: string): Promise<TavilySearchResult[]> {
    try {
      const response = await fetch('https://api.tavily.com/search', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.tavilyApiKey}`
        },
        body: JSON.stringify({
          query,
          search_depth: 'basic',
          include_answer: false,
          include_images: false,
          include_raw_content: false,
          max_results: 5
        })
      });

      if (!response.ok) {
        throw new Error(`Tavily API error: ${response.statusText}`);
      }

      const data = await response.json();
      
      return data.results?.map((result: any) => ({
        title: result.title,
        url: result.url,
        content: result.content,
        score: result.score || 0
      })) || [];
    } catch (error) {
      console.error('Error searching web:', error);
      return [];
    }
  }

  private isPersonalQuestion(question: string): boolean {
    const personalKeywords = [
      'kh√°nh duy', 'b√πi', 'ai engineer', 'portfolio', 'kinh nghi·ªám', 
      'h·ªçc v·∫•n', 'k·ªπ nƒÉng', 'd·ª± √°n', 'c√¥ng vi·ªác', 'li√™n h·ªá',
      'th√¥ng tin c√° nh√¢n', 'cv', 'resume', 'background'
    ];
    
    const lowerQuestion = question.toLowerCase();
    return personalKeywords.some(keyword => lowerQuestion.includes(keyword));
  }

  getVectorStore(): VectorStore {
    return this.vectorStore;
  }
}
